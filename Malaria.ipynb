{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/POOJACH76/API_ecommerce/blob/master/Malaria.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DSJc9r0GKl6f"
      },
      "outputs": [],
      "source": [
        "! mkdir -p ~/.kaggle\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0oLKLioKoxh",
        "outputId": "3a2bd9c5-3c38-4658-b753-d32d6f49272a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading cell-images-for-detecting-malaria.zip to /content\n",
            " 97% 658M/675M [00:07<00:00, 18.2MB/s]\n",
            "100% 675M/675M [00:08<00:00, 88.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d iarunava/cell-images-for-detecting-malaria"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5CsOosf1Ko5k"
      },
      "outputs": [],
      "source": [
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LBiQJy3lKpHY"
      },
      "outputs": [],
      "source": [
        "zip_ref= zipfile.ZipFile(\"/content/cell-images-for-detecting-malaria.zip\",'r')\n",
        "zip_ref.extractall('/content')\n",
        "\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-BGNHM0rKpOJ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5Ahn6pZXEhK",
        "outputId": "4953fa7c-da12-45da-9606-d5ad9317a077"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WvtI6I1iKpce"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE=[224,224]\n",
        "train_path=\"/content/cell_images/Parasitized\"\n",
        "validation_path=\"/content/cell_images/Uninfected\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sWPof606sCdu"
      },
      "outputs": [],
      "source": [
        "\n",
        "datagen = ImageDataGenerator(featurewise_center=False,\n",
        "                             samplewise_center=False,\n",
        "                             featurewise_std_normalization=False,\n",
        "                             samplewise_std_normalization=False,\n",
        "                             zca_whitening=False,\n",
        "                             rotation_range=10,\n",
        "                             zoom_range=0.1,\n",
        "                             width_shift_range=0.1,\n",
        "                             height_shift_range=0.1,\n",
        "                             horizontal_flip=False,\n",
        "                             vertical_flip=False,\n",
        "                             rescale=1/255.0,\n",
        "                             validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y26hQ459vR_-",
        "outputId": "0be17b82-fcd4-48a8-a8d9-eb1d50358fe6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83683744/83683744 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from keras.applications.xception import Xception, preprocess_input\n",
        "xception_wo_top = Xception(include_top=False, weights='imagenet', input_tensor=None, input_shape=(71,71,3), pooling=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TJxALGMVfzj",
        "outputId": "a60520e9-ac42-4ab5-b79b-c2d45a32968d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 27558 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "Data = datagen.flow_from_directory(\n",
        "    directory='/content/cell_images/cell_images',\n",
        "    target_size=(71, 71),\n",
        "    class_mode='binary',\n",
        "    batch_size=16,\n",
        "    subset='training',\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Sn3BEWttz9Dj"
      },
      "outputs": [],
      "source": [
        "#Normalize\n",
        "def process (image,label):\n",
        "  image= tf.cast(image/255. ,tf.float32)\n",
        "  return image,label\n",
        "  acne_ds= acne_ds.map(process)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO4cHqTEKpit",
        "outputId": "c0a595d9-1c91-4424-e8ae-3ac062ef1c1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 254, 254, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 127, 127, 32)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 125, 125, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 62, 62, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 60, 60, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 30, 30, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 115200)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               14745728  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14847297 (56.64 MB)\n",
            "Trainable params: 14847297 (56.64 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), padding='valid', activation='relu', input_shape=(256, 256, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid'))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), padding='valid', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid'))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), padding='valid', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid'))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPdFyVZvKpy3",
        "outputId": "ff10c07b-6be7-4efe-c61b-3b0b9a20598c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 44095 images belonging to 3 classes.\n",
            "Found 11021 images belonging to 3 classes.\n",
            "Epoch 1/10\n",
            "2756/2756 [==============================] - 173s 61ms/step - loss: -101951492587520.0000 - accuracy: 0.2500 - val_loss: -516987662893056.0000 - val_accuracy: 0.2500\n",
            "Epoch 2/10\n",
            "2756/2756 [==============================] - 160s 58ms/step - loss: -3198883320561664.0000 - accuracy: 0.2500 - val_loss: -7822700424724480.0000 - val_accuracy: 0.2500\n",
            "Epoch 3/10\n",
            "2756/2756 [==============================] - 160s 58ms/step - loss: -20199439499001856.0000 - accuracy: 0.2500 - val_loss: -36580880705126400.0000 - val_accuracy: 0.2500\n",
            "Epoch 4/10\n",
            "2756/2756 [==============================] - 156s 57ms/step - loss: -71446742314254336.0000 - accuracy: 0.2500 - val_loss: -111999698969034752.0000 - val_accuracy: 0.2500\n",
            "Epoch 5/10\n",
            "2756/2756 [==============================] - 169s 61ms/step - loss: -187016499704102912.0000 - accuracy: 0.2500 - val_loss: -267447304284274688.0000 - val_accuracy: 0.2500\n",
            "Epoch 6/10\n",
            "2756/2756 [==============================] - 158s 57ms/step - loss: -408254920865611776.0000 - accuracy: 0.2500 - val_loss: -548829372262383616.0000 - val_accuracy: 0.2500\n",
            "Epoch 7/10\n",
            "2756/2756 [==============================] - 159s 58ms/step - loss: -788037575813103616.0000 - accuracy: 0.2500 - val_loss: -1012859391268880384.0000 - val_accuracy: 0.2500\n",
            "Epoch 8/10\n",
            "2756/2756 [==============================] - 156s 57ms/step - loss: -1391981995642322944.0000 - accuracy: 0.2500 - val_loss: -1733674750305107968.0000 - val_accuracy: 0.2500\n",
            "Epoch 9/10\n",
            "2756/2756 [==============================] - 168s 61ms/step - loss: -2308034885643665408.0000 - accuracy: 0.2500 - val_loss: -2801801368422055936.0000 - val_accuracy: 0.2500\n",
            "Epoch 10/10\n",
            "2756/2756 [==============================] - 158s 57ms/step - loss: -3626643446707519488.0000 - accuracy: 0.2500 - val_loss: -4306114969516113920.0000 - val_accuracy: 0.2500\n",
            "Found 11021 images belonging to 3 classes.\n",
            "689/689 [==============================] - 31s 44ms/step\n",
            "Accuracy: 0.25\n",
            "Precision: 0.25\n",
            "Recall: 0.25\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,\n",
        "    validation_split=0.2,\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=False,\n",
        "    vertical_flip=False\n",
        ")\n",
        "\n",
        "train_datagen = datagen.flow_from_directory(\n",
        "    directory='/content/cell_images',\n",
        "    target_size=(71, 71),\n",
        "    class_mode='binary',\n",
        "    batch_size=16,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "valid_datagen = datagen.flow_from_directory(\n",
        "    directory='/content/cell_images',\n",
        "    target_size=(71, 71),\n",
        "    class_mode='binary',\n",
        "    batch_size=16,\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), padding='valid', activation='relu', input_shape=(71, 71, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid'))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), padding='valid', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid'))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), padding='valid', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "num_epochs = 10\n",
        "model.fit(train_datagen, epochs=num_epochs, validation_data=valid_datagen)\n",
        "\n",
        "test_datagen = datagen.flow_from_directory(\n",
        "    directory='/content/cell_images',\n",
        "    target_size=(71, 71),\n",
        "    class_mode='binary',\n",
        "    batch_size=16,\n",
        "    subset='validation',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "predictions = model.predict(test_datagen)\n",
        "predicted_labels = (predictions > 0.5).astype(int)\n",
        "true_labels = test_datagen.labels\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "precision = precision_score(true_labels, predicted_labels, average='micro')\n",
        "recall = recall_score(true_labels, predicted_labels, average='micro')\n",
        "\n",
        "\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print(f'Precision: {precision:.2f}')\n",
        "print(f'Recall: {recall:.2f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model using TensorFlow's built-in method\n",
        "model.save(\"trained_model.h5\")\n",
        "\n",
        "# Later, you can load the model using TensorFlow\n",
        "loaded_model = tf.keras.models.load_model(\"trained_model.h5\")"
      ],
      "metadata": {
        "id": "hp3YO1B_6MjR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zYLS8Nxd6MnG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "f6i0FO7xKqIu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "d1ef6cd7-9220-438f-c3fe-a7e9c7cd3341"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "OpenCV(4.8.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-82175cdb944a>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtest_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/maleria.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtest_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m71\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m71\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mtest_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_img\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtest_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "model = load_model('trained_model.h5')\n",
        "\n",
        "\n",
        "test_img = cv2.imread('/content/maleria.png')\n",
        "test_img = cv2.resize(test_img, (71, 71))\n",
        "test_img = test_img / 255.0\n",
        "test_input = np.expand_dims(test_img, axis=0)\n",
        "\n",
        "\n",
        "predictions = model.predict(test_input)\n",
        "\n",
        "\n",
        "class_labels = [\"infected\",\"Not infected\"]\n",
        "\n",
        "\n",
        "predicted_class_index = np.argmax(predictions)\n",
        "predicted_class = class_labels[predicted_class_index]\n",
        "\n",
        "plt.imshow(test_img)\n",
        "plt.title(f\"Prediction: {predicted_class}\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTeLbeOXKqUN"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Et-T7nifeBdG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOOH22sQzLFD12B0r6z4sRD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}